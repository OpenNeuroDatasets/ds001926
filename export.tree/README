1. Data structure

my_dataset/
├── README.mat 							# This file, Contains experimental design/task details, imaging parameters, and description of the directory structure
├── sub-01/								
	├── ses-day1								# Data of the first fMRI session (day 1)
	│   ├── anat
	│   │   ├── sub-01_ses-day1_T1w.nii.gz		# raw 3-D structural image (T1-weighted magnetization prepared rapid acquisition gradient-echo image)
	│	│   ├── sub-01_ses-day1_run-01_T2w.nii.gz		# T2-weighted turbo spin echo image for hippocampal segmentation
	│   │   └── sub-01_ses-day1_run-02_T2w.nii.gz
	│	├── fmap
	│   │   ├── sub-01_ses-day1_fieldmap.nii.gz		# Field map image to correct B0 inhomogeneities 
	│   │   ├── sub-01_ses-day1_magnitude.nii.gz
	│	│
	│   └── func
	│       ├── sub-01_ses-day1_task-study_run-01_bold.nii.gz			# Raw 4-D functional image of a study phase (run 1-6)
	│       ├── sub-01_ses-day1_task-study_run-02_bold.nii.gz
	│       ├── sub-01_ses-day1_task-study_run-03_bold.nii.gz
	│       ├── sub-01_ses-day1_task-study_run-04_bold.nii.gz
	│       ├── sub-01_ses-day1_task-study_run-05_bold.nii.gz
	│       └── sub-01_ses-day1_task-study_run-06_bold.nii.gz
	│ 
	└── ses-day2
	    ├── anat
	    │   └── sub-01_ses-day2_T1w.nii.gz		# raw 3-D structural image (T1-weighted magnetization prepared rapid acquisition gradient-echo image)
		├── fmap
	    │   ├── sub-01_ses-day2_fieldmap.nii.gz			# Field map image to correct B0 inhomogeneities
	    │   ├── sub-01_ses-day2_magnitude.nii.gz
	    └── func
	    │   ├── sub-01_ses-day2_task-localizer_run-01_bold.nii.gz		# Raw 4-D functional image of a face/scene/object localizer phase (run 1-3)
	    │   ├── sub-01_ses-day2_task-localizer_run-02_bold.nii.gz
	    │   ├── sub-01_ses-day2_task-localizer_run-03_bold.nii.gz
	    │   ├── sub-01_ses-day2_task-post_run-01_bold.nii.gz			# Raw 4-D functional image of a post-learning phase (run 1-2)
	    │   ├── sub-01_ses-day2_task-post_run-02_bold.nii.gz
	    │   ├── sub-01_ses-day2_task-test_run-01_bold.nii.gz			# Raw 4-D functional image of a memory test phase (run 1-2)
	    │   └── sub-01_ses-day2_task-test_run-02_bold.nii.gz
	    └── 
├── derivatives/
	├── DESIGN.mat 							# Descriptions of design matrixes (in design_matrix folder)
    ├── sub-01/									
		├── ses-day1								# Data of the first fMRI session (day 1)
		│   ├── design_matrix
		│       ├── sub-01_study_01.mat			# Design matrixes of study runs (1-6)
		│       ├── sub-01_study_02.mat
		│       ├── sub-01_study_03.mat
		│       ├── sub-01_study_04.mat
		│       ├── sub-01_study_05.mat
		│       └── sub-01_study_06.mat
		└── ses-day2
	    	├── design_matrix				
	        	├── sub-01_localizer_01.mat		# Design matrixes of localizer runs (1-3)
	        	├── sub-01_localizer_02.mat
	        	├── sub-01_localizer_03.mat
	        	├── sub-01_post_01.mat			# Design matrixes of post-learning runs (1-2)
	        	├── sub-01_post_02.mat
	        	├── sub-01_test_01.mat			# Design matrixes of memory test runs (1-2)
	        	└── sub-01_test_02.mat


2. Study procedure (see http://www.jneurosci.org/content/37/8/2022?rss=1 for details)

The experimental procedure unfolded over 2 d (Fig. 2A). All phases of the experiment were scanned with fMRI. The first session consisted of six runs of an incidental encoding task. Participants made indoor/outdoor judgments for scenes that were presented for most of trials (92%) and female/male judgments for faces that were presented occasionally (8%). Unbeknownst to participants, the stimulus sequence contained scene image pairs (e.g., scene A–scene B). There were 8 new pairs for each of the 2 conditions (violation and nonviolation) within each run (8 pairs 6 runs 48 pairs in total per condition). The first and second members of each pair were presented once separately (randomly intermixed with items from other pairs) before they were ever shown together in a pair. This allowed us to measure the neural representation of each item on its own before learning (“prelearning snapshot”) and uncontaminated by the pair-mate (Schapiro et al., 2012). There was no explicit distinction between the prelearning snapshots and the presentation of pairs. After the items in a given pair were shown separately (to acquire prelearning snapshots), the items were shown as a pair three times, interleaved with repetitions of other pairs. For pairs assigned to the violation condition, the three repetitions were followed by a violation event where the first scene in the pair was followed by a novel face instead of the paired scene (e.g., scene A–face X); this event was omitted for nonviolation pairs. Crucially, in both conditions, the B item was subsequently presented (“restudied”) on its own, following a novel item in the sequence rather than its previous context A. This cycle of violation and restudy was repeated once more for the violation pairs— our modeling work suggested that two cycles would produce more differentiation than one—leading to the following overall event sequence per pair: AB–AB–AB–AX–B–AY–B. There was also a second restudy for the nonviolation pairs, leading to a sequence that was matched for the number of exposures to B, but without violation events: AB–AB–AB– B–B. Importantly, these manipulations were incidental to the primary task of making categorical judgments and the interleaving of multiple pairs obscured the pair structure. In a separate behavioral pilot, we encouraged participants to report any regularity and none noticed that the sequence was constructed from repeated pairs. Each trial began with a blink of the fixation cross to signal an upcoming stimulus, followed by the stimulus presentation for 1 s and a blank interval of 2 s. There were a total of 192 trials (32 prelearning, 160 pair sequences) within each run, which lasted 10 min and 6 s. The second session occurred the day after the first session (at least 12 h) and consisted of three tasks: postlearning snapshot (two runs), surprise memory test (two runs), and functional localizer (three runs). The postlearning snapshots were collected in the same manner as the prelearning snapshots: all scenes from the first session were shown again, one at a time, in a random order and with indoor/outdoor judgments. In the recognition memory test, we presented each participant with all B scenes from both conditions (48 violation and 48 nonviolation) randomly intermixed with 48 novel scenes. A two-step memory response was made for each scene (“old” or “new”) and then confidence level (“sure” or “unsure”). Images remained on the screen until the responses were made and the next trial began on the first subsequent TR. The four postlearning and memory runs were interleaved and their order was counterbalanced across participants (odd participants: memory run 1, postlearning run 1, postlearning run 2, memory run 2; even participants: postlearning run 1, memory run 1, memory run 2, postlearning run 2). Half of the studied pairs were randomly assigned to memory run 1 and postlearning run 1 and the other half to memory run 2 and postlearning run 2. As a result of this design, for half of the B items, memory was tested before the postlearning snapshot was taken and, for the other half of B items, the postlearning snapshot was taken before memory was tested (Fig. 2B). We designed the procedure this way be- cause we were concerned that testing memory for an item could contaminate the subsequent postlearning snapshot for that item and vice versa. We wanted some items to get an uncontaminated postlearning snapshot (before memory was tested). Although behavioral recognition memory performance was not the focus of this study, we also wanted some items to get an uncontaminated memory judgment (before the snapshot was taken). For the analyses focusing on neural differentiation (and related follow-up analyses), we used only the pairs for which the postlearning snapshot preceded the recognition memory test, thereby ensuring that the postlearning snapshot would not be affected by any learning that occurred as a result of recognition memory test. After the postlearning and memory runs, participants completed three runs of a functional localizer. Each run contained 15 blocks, with five blocks from each of three categories: faces, scenes, and objects. Participants judged faces as male or female, scenes as indoor or outdoor, and objects as manmade or natural. Each stimulus was presented for 500 ms, followed by a blank interval of 1000 ms. There were 10 trials per block and each 15 s block was followed by 15 s of fixation, treated as a rest category. The duration of each run was 465 s. For the analyses below, we used only the scene blocks. Specifically, we calculated a “template” activity pattern for the scene category from the scene blocks; this template was later used to evaluate whether our results were item specific.


3. fMRI data acquisition

The experiment was programmed in MATLAB using the Psychophysics Toolbox http://psychtoolbox.org . MRI data were acquired with a 3T MRI scanner (Siemens Prisma) with a 64-channel head coil. Functional scans came from a T2*-weighted multiband EPI sequence (TR 1.5 s, TE 39 ms, 128 128 matrix, voxel size 1.5 mm iso, 192 mm field of view, flip angle 50°, acceleration factor 4, shift 3), with 52 oblique axial slices (transverse to the long axis of the hippocampus) acquired in an interleaved order. These slices covered a partial volume encompassing the temporal and occipital lobes, which allowed us to maximize spatial and temporal resolution over hippocampal subfields. A whole-brain T1 MPRAGE image. Two T2 TSE images were acquired for probabilistic segmentation of hippocampal subfields (54 slices perpendicular to the long axis of the hippocampus; 0.44 0.44 mm in-plane, 1.8 mm thick). A field map was acquired to correct for B0 inhomogeneity. 